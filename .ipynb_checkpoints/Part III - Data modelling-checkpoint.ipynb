{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data modelling\n",
    "**Part 3**\n",
    "\n",
    "This is a classification problem where the target variable edibility is either 'e' (edible) or 'p' (poisonous). In this stage of the project - after feature selection and cleaning - there are **115 features** in each row of data that all have to be used to classify the edibility of the specimen. \n",
    "\n",
    "## Methodology\n",
    "Considering the high number of predictor variables(100), the algorithms used for classifying the edibility are decision tree, random forest, and support vector machine because these algorithms have superior accuracy and computational performance on high dimensional data compared to other conventional classifiers like Stochastic gradient descent, K-nearest neighbours, and Naive bayesian classifiers. \n",
    "\n",
    "Logistic regression might be a better alternative for deployment\n",
    "\n",
    "Utilizing more than 1 model gives me a baseline model for comparison that will eliminate the possibility of oversight in this experiment when determining the causality of machine learning performance. I will test these models with exhaustive grid search to optimize the hyperparamaters, and compare them against a baseline model with the default hyperparameter values.\n",
    "\n",
    "## Real-life considerations\n",
    "In real life applications, a binary classifier predicicting the edibility of something isn't the safest or most useful model to use. If classification was performed for the production of consumable or medicine, there is a vastly high risk of consuming a poisonous product that was wrongly classified as edible. Logistic regression that returns the probability of toxicity is more useful. \n",
    "\n",
    "However binary classification still has some value when using the metrics of a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7821, 102)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-surface_f</th>\n",
       "      <th>cap-surface_g</th>\n",
       "      <th>cap-surface_s</th>\n",
       "      <th>cap-surface_y</th>\n",
       "      <th>cap-color_b</th>\n",
       "      <th>cap-color_c</th>\n",
       "      <th>cap-color_e</th>\n",
       "      <th>cap-color_g</th>\n",
       "      <th>cap-color_n</th>\n",
       "      <th>cap-color_p</th>\n",
       "      <th>...</th>\n",
       "      <th>population_y</th>\n",
       "      <th>habitat_d</th>\n",
       "      <th>habitat_g</th>\n",
       "      <th>habitat_l</th>\n",
       "      <th>habitat_m</th>\n",
       "      <th>habitat_p</th>\n",
       "      <th>habitat_u</th>\n",
       "      <th>habitat_w</th>\n",
       "      <th>edibility_e</th>\n",
       "      <th>edibility_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-surface_f  cap-surface_g  cap-surface_s  cap-surface_y  cap-color_b  \\\n",
       "0              0              0              1              0            0   \n",
       "1              0              0              1              0            0   \n",
       "2              0              0              1              0            0   \n",
       "3              0              0              0              1            0   \n",
       "4              0              0              1              0            0   \n",
       "\n",
       "   cap-color_c  cap-color_e  cap-color_g  cap-color_n  cap-color_p  ...  \\\n",
       "0            0            0            0            1            0  ...   \n",
       "1            0            0            0            0            0  ...   \n",
       "2            0            0            0            0            0  ...   \n",
       "3            0            0            0            0            0  ...   \n",
       "4            0            0            1            0            0  ...   \n",
       "\n",
       "   population_y  habitat_d  habitat_g  habitat_l  habitat_m  habitat_p  \\\n",
       "0             0          0          0          0          0          0   \n",
       "1             0          0          1          0          0          0   \n",
       "2             0          0          0          0          1          0   \n",
       "3             0          0          0          0          0          0   \n",
       "4             0          0          1          0          0          0   \n",
       "\n",
       "   habitat_u  habitat_w  edibility_e  edibility_p  \n",
       "0          1          0            0            1  \n",
       "1          0          0            1            0  \n",
       "2          0          0            1            0  \n",
       "3          1          0            0            1  \n",
       "4          0          0            1            0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"agaricus-lepiota_processed.data\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling process\n",
    "1. Wrangle the one hot encoded edibility columns into a single edibility column\n",
    "2. Split the data into train and test with a 80-20 split\n",
    "3. Set up and train the model objects\n",
    "    * Decision tree +  Eshaustive grid search\n",
    "    * Random forest +  Eshaustive grid search\n",
    "4. Evaluate the models, compare: \n",
    "    * baseline model and grid search model\n",
    "    * grid search model: training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-surface_f</th>\n",
       "      <th>cap-surface_g</th>\n",
       "      <th>cap-surface_s</th>\n",
       "      <th>cap-surface_y</th>\n",
       "      <th>cap-color_b</th>\n",
       "      <th>cap-color_c</th>\n",
       "      <th>cap-color_e</th>\n",
       "      <th>cap-color_g</th>\n",
       "      <th>cap-color_n</th>\n",
       "      <th>cap-color_p</th>\n",
       "      <th>...</th>\n",
       "      <th>population_v</th>\n",
       "      <th>population_y</th>\n",
       "      <th>habitat_d</th>\n",
       "      <th>habitat_g</th>\n",
       "      <th>habitat_l</th>\n",
       "      <th>habitat_m</th>\n",
       "      <th>habitat_p</th>\n",
       "      <th>habitat_u</th>\n",
       "      <th>habitat_w</th>\n",
       "      <th>edibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-surface_f  cap-surface_g  cap-surface_s  cap-surface_y  cap-color_b  \\\n",
       "0              0              0              1              0            0   \n",
       "1              0              0              1              0            0   \n",
       "2              0              0              1              0            0   \n",
       "3              0              0              0              1            0   \n",
       "4              0              0              1              0            0   \n",
       "\n",
       "   cap-color_c  cap-color_e  cap-color_g  cap-color_n  cap-color_p  ...  \\\n",
       "0            0            0            0            1            0  ...   \n",
       "1            0            0            0            0            0  ...   \n",
       "2            0            0            0            0            0  ...   \n",
       "3            0            0            0            0            0  ...   \n",
       "4            0            0            1            0            0  ...   \n",
       "\n",
       "   population_v  population_y  habitat_d  habitat_g  habitat_l  habitat_m  \\\n",
       "0             0             0          0          0          0          0   \n",
       "1             0             0          0          1          0          0   \n",
       "2             0             0          0          0          0          1   \n",
       "3             0             0          0          0          0          0   \n",
       "4             0             0          0          1          0          0   \n",
       "\n",
       "   habitat_p  habitat_u  habitat_w  edibility  \n",
       "0          0          1          0          p  \n",
       "1          0          0          0          e  \n",
       "2          0          0          0          e  \n",
       "3          0          1          0          p  \n",
       "4          0          0          0          e  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edibility(row):\n",
    "    for c in row.index:\n",
    "        if row[c] == 1:\n",
    "            return c[-1]\n",
    "        \n",
    "data_copy = data.copy()\n",
    "\n",
    "data_copy['edibility'] = data_copy.iloc[:,-2:].apply(edibility, axis=1)\n",
    "data_copy = data_copy.drop(['edibility_e','edibility_p'], axis=1)\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric selection and configuring settings\n",
    "\n",
    "The target attribute is a binary class label, accuracy score is the only possible metric. Checking the cpu count to set up the gridsearch object properly.\n",
    "\n",
    "Determine the suitability of sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# simple test of accuracy_score on target variable\n",
    "a1 = np.array(['p','p','p','p','p'])\n",
    "a2 = np.array(['p','p','p','e','e'])\n",
    "print(accuracy_score(a1, a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_copy.iloc[:,:-1]\n",
    "y = data_copy.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 6256\n",
      "testing samples: 1565\n"
     ]
    }
   ],
   "source": [
    "print('training samples: '+str(len(X_train)))\n",
    "print('testing samples: '+str(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt= DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'criterion':['gini','entropy'], \n",
    "              'max_depth':list(range(30,90,10)), \n",
    "              'min_samples_split':[1, 0.0025, 0.005, 0.01, 0.02],\n",
    "              'min_samples_leaf':[1, 0.0025, 0.005, 0.01, 0.02, 0.04], \n",
    "              'max_features':list(range(1,11,1))} #there are 100 features, square root of 100 is 10\n",
    "\n",
    "gridsearch_dt_class = GridSearchCV(estimator = dt,\n",
    "                     param_grid = param_grid,\n",
    "                     scoring = 'accuracy',\n",
    "                     n_jobs = 6,\n",
    "                     cv = None, #Turning off cross fold validation for performance\n",
    "                     refit= True, \n",
    "                     return_train_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=6,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [30, 40, 50, 60, 70, 80],\n",
       "                         'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_leaf': [1, 0.0025, 0.005, 0.01, 0.02,\n",
       "                                              0.04],\n",
       "                         'min_samples_split': [1, 0.0025, 0.005, 0.01, 0.02]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_dt_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 60, 'max_features': 8, 'min_samples_leaf': 1, 'min_samples_split': 0.0025}\n"
     ]
    }
   ],
   "source": [
    "print(gridsearch_dt_class.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline tree accuracy: 1.0\n",
      "gridsearch tree accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Comparing the accuracy of a baseline model and the gridsearch model\n",
    "dt_control = DecisionTreeClassifier()\n",
    "y_ = dt_control.fit(X_train, y_train).predict(X_test)\n",
    "acc = accuracy_score(y_test, y_)\n",
    "print(f'baseline tree accuracy: {acc}')\n",
    "\n",
    "y_2 = gridsearch_dt_class.best_estimator_.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_2)\n",
    "print(f'gridsearch tree accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set gridsearch tree accuracy: 0.9988810741687979\n",
      "testing set gridsearch tree accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# gridsearch training set accuracy vs testing set accuracy\n",
    "y_ = gridsearch_dt_class.predict(X_train)\n",
    "acc = accuracy_score(y_train, y_)\n",
    "print(f'training set gridsearch tree accuracy: {acc}')\n",
    "\n",
    "y_ = gridsearch_dt_class.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_)\n",
    "print(f'testing set gridsearch tree accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'criterion':['gini','entropy'], \n",
    "              'max_depth':list(range(30,90,10)), \n",
    "              'min_samples_split':[1, 0.0025, 0.005, 0.01, 0.02],\n",
    "              'min_samples_leaf':[1, 0.0025, 0.005, 0.01, 0.02, 0.04], \n",
    "              'max_features':list(range(1,11,1))} #there are 100 features, square root of 100 is 10\n",
    "\n",
    "gridsearch_rf_class = GridSearchCV(estimator = rf,\n",
    "                     param_grid = param_grid,\n",
    "                     scoring = 'accuracy',\n",
    "                     n_jobs = 6,\n",
    "                     cv = None, #Turning off cross fold validation for performance\n",
    "                     refit= True, \n",
    "                     return_train_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\INSTALLATION_FOLDER\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=6,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [30, 40, 50, 60, 70, 80],\n",
       "                         'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_leaf': [1, 0.0025, 0.005, 0.01, 0.02,\n",
       "                                              0.04],\n",
       "                         'min_samples_split': [1, 0.0025, 0.005, 0.01, 0.02]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_rf_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 30, 'max_features': 1, 'min_samples_leaf': 1, 'min_samples_split': 0.0025}\n"
     ]
    }
   ],
   "source": [
    "print(gridsearch_rf_class.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline random forest accuracy: 1.0\n",
      "gridsearch random forest accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Comparing the accuracy of a baseline model and the gridsearch model\n",
    "rf_control = RandomForestClassifier()\n",
    "y_ = rf_control.fit(X_train.to_numpy().squeeze(), y_train.to_numpy().squeeze()).predict(X_test)\n",
    "acc = accuracy_score(y_test, y_)\n",
    "print(f'baseline random forest accuracy: {acc}')\n",
    "\n",
    "y_2 = gridsearch_rf_class.best_estimator_.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_2)\n",
    "print(f'gridsearch random forest accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set gridsearch random forest accuracy: 1.0\n",
      "testing set gridsearch random forest accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# gridsearch training set accuracy vs testing set accuracy\n",
    "y_ = gridsearch_rf_class.predict(X_train)\n",
    "acc = accuracy_score(y_train, y_)\n",
    "print(f'training set gridsearch random forest accuracy: {acc}')\n",
    "\n",
    "y_ = gridsearch_rf_class.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_)\n",
    "print(f'testing set gridsearch random forest accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "              \n",
    "param_grid = {'kernel':['linear','rbf','polynomial','sigmoid'],\n",
    "              'C':[.001, .1, 1, 10, 100]}\n",
    "\n",
    "gridsearch_svm_class = GridSearchCV(estimator = svm,\n",
    "                     param_grid = param_grid,\n",
    "                     scoring = 'accuracy',\n",
    "                     n_jobs = 6,\n",
    "                     cv = None, #Turning off cross fold validation for performance\n",
    "                     refit= True, \n",
    "                     return_train_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=6,\n",
       "             param_grid={'C': [0.001, 0.1, 1, 10, 100],\n",
       "                         'kernel': ['linear', 'rbf', 'polynomial', 'sigmoid']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_svm_class.fit(X_train.to_numpy().squeeze(), y_train.to_numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(gridsearch_svm_class.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline random forest accuracy: 1.0\n",
      "gridsearch random forest accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Comparing the accuracy of a baseline model and the gridsearch model\n",
    "\n",
    "svm_control = SVC()\n",
    "y_ = svm_control.fit(X_train.to_numpy().squeeze(), y_train.to_numpy().squeeze()).predict(X_test)\n",
    "acc = accuracy_score(y_test, y_)\n",
    "print(f'baseline random forest accuracy: {acc}')\n",
    "\n",
    "y_2 = gridsearch_svm_class.best_estimator_.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_2)\n",
    "print(f'gridsearch random forest accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p', 'p', 'p', ..., 'e', 'p', 'p'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_svm_class.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set gridsearch SVM accuracy: 1.0\n",
      "testing set gridsearch SVM accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# gridsearch training set accuracy vs testing set accuracy\n",
    "y_ = gridsearch_svm_class.best_estimator_.predict(X_train)\n",
    "acc = accuracy_score(y_train, y_)\n",
    "print(f'training set gridsearch SVM accuracy: {acc}')\n",
    "\n",
    "y_ = gridsearch_svm_class.best_estimator_.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_)\n",
    "print(f'testing set gridsearch SVM accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "training samples: 6256\n",
    "\n",
    "testing samples: 1565\n",
    "\n",
    "| Accuracy (%) | Baseline  | Gridsearch  | Gridsearch train   | Gridsearch test   |\n",
    "|---:|:-------------|:-----------|:------|:------|\n",
    "| Decision Tree | 1.0  | 1.0  | 1.0   | 1.0     |\n",
    "| Random Forest | 1.0  | 1.0    | 1.0   | 1.0     |\n",
    "| Support Vector | 1.0  | 1.0    | 1.0   | 1.0     |\n",
    "\n",
    "\n",
    "High accuracy values >0.999 of all classifiers\n",
    "\n",
    "## Decision tree\n",
    "The accuracy values of all the tests are at 1.0 meaning that the classifiers are fully accurate on the training data and the test data, with and without exhaustive gridsearch\n",
    "\n",
    "An examination of the hyperparamters of the gridsearch model show that min_samples_leaf has a value of 1 - which is the highest value of in the list of the parameter grid. The value needs to be increased for more accurate\n",
    "\n",
    "## Random forest \n",
    "The accuracy values of all the tests are at 1.0 meaning that the classifiers are fully accurate on the training data and the test data, with and without exhaustive gridsearch. However, I need to test lower values of the max_depth parameter on more data to acquire a more optimized model that might work better on other data.\n",
    "\n",
    "The random forest same grid search has the same hyperparameter ranges as decision tree yet was able to retain full and constant classification accuracy midly suggesting that the accuracy of the random forest classifier is not detrimented by un-optimal hyperparameters \n",
    "\n",
    "## Support Vector machine\n",
    "The accuracy values of all the tests are at 1.0 meaning that the classifiers are fully accurate on the training data and the test data, with and without exhaustive gridsearch.\n",
    "\n",
    "I would put either this or random forest into production due to the high accuracy of the untuned model and \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
